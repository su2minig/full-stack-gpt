{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `WikipediaSearchTool` with `{'query': 'Research about the XZ backdoor'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: XZ Utils backdoor\n",
      "Summary: On 29 March 2024, software developer Andres Freund reported that he had found a maliciously introduced backdoor in the Linux utility xz within the liblzma library in versions 5.6.0 and 5.6.1 released in February 2024.While xz is commonly present in most Linux distributions, the backdoor only targeted Debian- and RPM-based systems running on the x86-64 architecture. At the time of discovery the backdoored version had not yet been widely deployed to production systems, but was present in development versions of major distributions.The backdoor gives an attacker who possesses a specific Ed448 private key remote code execution capabilities on the affected Linux systems. The issue has been assigned a CVSS score of 10.0, the highest possible score.\n",
      "\n",
      "\n",
      "\n",
      "Page: Supply chain attack\n",
      "Summary: A supply chain attack is a cyber-attack that seeks to damage an organization by targeting less secure elements in the supply chain. A supply chain attack can occur in any industry, from the financial sector, oil industry, to a government sector. A supply chain attack can happen in software or hardware. Cybercriminals typically tamper with the manufacturing or distribution of a product by installing malware or hardware-based spying components. Symantec's 2019 Internet Security Threat Report states that supply chain attacks increased by 78 percent in 2018. A supply chain is a system of activities involved in handling, distributing, manufacturing, and processing goods in order to move resources from a vendor into the hands of the final consumer. A supply chain is a complex network of interconnected players governed by supply and demand.Although supply chain attack is a broad term without a universally agreed upon definition, in reference to cyber-security, a supply chain attack involves physically tampering with electronics (computers, ATMs, power systems, factory data networks) in order to install undetectable malware for the purpose of bringing harm to a player further down the supply chain network.In a more general sense, a supply chain attack may not necessarily involve electronics. In 2010 when burglars gained access to the pharmaceutical giant Eli Lilly's supply warehouse, by drilling a hole in the roof and loading $80 million worth of prescription drugs into a truck, they could also have been said to carry out a supply chain attack. However, this article will discuss cyber attacks on physical supply networks that rely on technology; hence, a supply chain attack is a method used by cyber-criminals.\n",
      "\n",
      "Page: Timeline of computer viruses and worms\n",
      "Summary: This timeline of computer viruses and worms presents a chronological timeline of noteworthy computer viruses, computer worms, Trojan horses, similar malware, related research and events.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ToTxtTool` with `On 29 March 2024, software developer Andres Freund reported that he had found a maliciously introduced backdoor in the Linux utility xz within the liblzma library in versions 5.6.0 and 5.6.1 released in February 2024. While xz is commonly present in most Linux distributions, the backdoor only targeted Debian- and RPM-based systems running on the x86-64 architecture. At the time of discovery the backdoored version had not yet been widely deployed to production systems, but was present in development versions of major distributions. The backdoor gives an attacker who possesses a specific Ed448 private key remote code execution capabilities on the affected Linux systems. The issue has been assigned a CVSS score of 10.0, the highest possible score.`\n",
      "responded: I found information about the XZ backdoor. The backdoor was found in the Linux utility xz within the liblzma library in versions 5.6.0 and 5.6.1 released in February 2024. The backdoor targeted Debian- and RPM-based systems running on the x86-64 architecture, giving an attacker remote code execution capabilities on affected Linux systems. The issue has been assigned a CVSS score of 10.0, the highest possible score.\n",
      "\n",
      "I will now extract this information and save it as a text file.\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mFile written successfully to output.txt.\u001b[0m\u001b[32;1m\u001b[1;3mI have extracted the information about the XZ backdoor and saved it as a text file. You can download the file [here](output.txt).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': StringPromptValue(text='Search the Research about the XZ backdoor, go to the related website, extract the content with text, and save it as a txt file.'),\n",
       " 'output': 'I have extracted the information about the XZ backdoor and saved it as a text file. You can download the file [here](output.txt).'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Type\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper\n",
    "from langchain.agents.agent_toolkits import FileManagementToolkit\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1,)\n",
    "\n",
    "class SearchToolArgsSchema(BaseModel):\n",
    "  query: str = Field(\n",
    "    description=\"The query you will search for.Example query: Research about the XZ backdoor\"\n",
    "  )\n",
    "\n",
    "\n",
    "class WikipediaSearchTool(BaseTool):\n",
    "  name = \"WikipediaSearchTool\"\n",
    "  description = \"Use this tool to find the website for the given query.\"\n",
    "  args_schema: Type[SearchToolArgsSchema] = SearchToolArgsSchema\n",
    "  \n",
    "  def _run(self, query):\n",
    "    wiki = WikipediaAPIWrapper()\n",
    "    return wiki.run(query)\n",
    "  \n",
    "\n",
    "class DuckDuckGoSearchTool(BaseTool):\n",
    "  name = \"DuckDuckGoSearchTool\"\n",
    "  description = \"Use this tool to find the website for the given query.\"\n",
    "  args_schema: Type[SearchToolArgsSchema] = SearchToolArgsSchema\n",
    "\n",
    "  def _run(self, query):\n",
    "    ddg = DuckDuckGoSearchAPIWrapper()\n",
    "    return ddg.run(query)\n",
    "  \n",
    "\n",
    "class ToTxtTool(BaseTool):\n",
    "  name = \"ToTxtTool\"\n",
    "  description = \"Converts the output to a text file\"\n",
    "  \n",
    "  def _run(self, output):\n",
    "    tools = FileManagementToolkit(\n",
    "      root_dir=str(\".txt/\"),\n",
    "      selected_tools=[\"read_file\", \"write_file\", \"list_directory\"],\n",
    "    ).get_tools()\n",
    "    read_tool, write_tool, list_tool = tools\n",
    "    return write_tool.invoke({\"file_path\": \"output.txt\", \"text\": output})\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "  llm=llm,\n",
    "  verbose=True,\n",
    "  agent=AgentType.OPENAI_FUNCTIONS,\n",
    "  handle_parsing_errors=True,\n",
    "  tools=[\n",
    "    WikipediaSearchTool(),\n",
    "    DuckDuckGoSearchTool(),\n",
    "    ToTxtTool()\n",
    "  ],\n",
    ")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "  \"Search the {query}, go to the related website, extract the content with text, and save it as a txt file.\"\n",
    ")\n",
    "\n",
    "chain = ({\"query\": RunnablePassthrough()} | prompt | agent)\n",
    "\n",
    "chain.invoke(\"Research about the XZ backdoor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀🌌⏳content='🚀🌌⏳'\n",
      "🌌🌎👩‍🚀content='🌌🌎👩\\u200d🚀'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"movie\": \"Top Gun\",\n",
    "        \"answer\": \"\"\"\n",
    "        🛩️👨‍✈️🔥\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"The Godfather\",\n",
    "        \"answer\": \"\"\"\n",
    "        👨‍👨‍👦🔫🍝\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"movie\": \"The Martian\",\n",
    "        \"answer\": \"\"\"\n",
    "        🚀👨‍🚀🌌\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"What emoji can describe this {movie}?\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a movie expert, you give an answer with 3 emojis.\"),\n",
    "        example_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"What emoji can you describe this {movie} with?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "  return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | final_prompt | llm\n",
    "\n",
    "def invoke_chain(movie):\n",
    "    result = chain.invoke({\"movie\": movie})\n",
    "    memory.save_context(\n",
    "        {\"input\": movie},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "    \n",
    "invoke_chain(\"Interstellar\")\n",
    "invoke_chain(\"Gravity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_chain(\"What was the first movie I asked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_chain(\"What was the second movie I asked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_chain(\"What was the fourth movie I asked?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"history\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/document.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriver, \n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": RunnableLambda(load_memory),\n",
    "    }\n",
    "    | prompt \n",
    "    | llm\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        {'input': question},\n",
    "        {'output': result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='According to the document, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Is Aaronson guilty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='He wrote \"FREEDOM IS SLAVERY\" and then \"TWO AND TWO MAKE FIVE\" on the table.'\n",
      "content='Julia is a character who was involved with Winston in the novel.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m aa \u001b[38;5;241m=\u001b[39m RunnablePassthrough()\n\u001b[1;32m----> 3\u001b[0m \u001b[43maa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "aa = RunnablePassthrough()\n",
    "\n",
    "aa.invoke({\"hi\":\"hello\"}).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
